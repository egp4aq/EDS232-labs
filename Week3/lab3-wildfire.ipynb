{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d41e7de-5f0c-4baf-a37f-ec5dbe4f7428",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, roc_auc_score, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e492775e-957c-40b4-b64f-5de93dbea5e1",
   "metadata": {},
   "source": [
    "# Lab 4: Fire and Tree Mortality\n",
    "\n",
    "# About the data\n",
    "Wildfires are increasingly frequent and severe due to climate change. Predicting tree mortality following a wildfire is critical for forest management, ecosystem recovery, and carbon sequestration planning. In this lab, we will build a logistic regression model to predict the probability of tree mortality one year after a wildfire\n",
    "\n",
    "The database we'll be working with today includes observations of individual trees involved in prescribed fires and wildfires occurring over 35 years, from 1981 to 2016. It is drawn from a fire and tree mortality database from the US Forest Service (see data description for the full database here: [link](https://www.nature.com/articles/s41597-020-0522-7#Sec10)).\n",
    "\n",
    "The target variable we'll use is `yr1status`, which is a binary variable (0=alive, 1=dead).  This tells us if a tree has died one year after a fire event.\n",
    "\n",
    "The features we'll use are `YrFireName`, `Times_burned`, `Species`, `Genus_species`,\n",
    "    `DBH_cm`, `HT_m`, `CR_pre`, and `CR_post`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2c5ce6-eb43-4544-8b88-c306a7618c85",
   "metadata": {},
   "source": [
    "## Step 1: Check the metadata\n",
    "\n",
    "Look at the metadata and provide a description on what each variable represents in the Description column below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b239ac-123f-4458-bf2c-fc46dcf5cc0a",
   "metadata": {},
   "source": [
    "| Feature                     | Description                                                                                   |\n",
    "|-----------------------------|-----------------------------------------------------------------------------------------------| \n",
    "| yr1status                   | Tree status in year 1 post-fire\n",
    "| YrFireName                  | Year and name of the fire                                    \n",
    "| Times_burned                | The number of times this tree was burned                           \n",
    "| Species                     | Symbol for species                                                 \n",
    "| Genus_species               | Genus and species of tree                                      \n",
    "| DBH_cm                      | Diameter at breast height rounded to nearest 0.1 cm\n",
    "| HT_m                        | Pre-fire tree height rounded to nearest 0.01 m\n",
    "| CR_pre                      | Pre-fire live crown ratio. Crown length divided by tree height\n",
    "| CR_post                     | Post-fire live crown ratio. Crown length divided by tree height"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d355a0",
   "metadata": {},
   "source": [
    "## Step 2: Fetch  data\n",
    "Read in the data set and filter to retain only the variables of interest.  Then check for incomplete observations and remove any rows containing NaNs.  How many observations does that leave us with? **Print your answer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac926dc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1212242/1765753220.py:2: DtypeWarning: Columns (4,5,6,7,10,62,63) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  trees_dat = pd.read_csv('/courses/EDS232/Data/FTM_trees.csv')\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "trees_dat = pd.read_csv('/courses/EDS232/Data/FTM_trees.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60bfca02-42c4-4eaf-aabc-d31f9249ccbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select only the desired columns\n",
    "trees_dat = trees_dat[['yr1status','YrFireName','Times_burned','Species','Genus_species','DBH_cm','HT_m','CR_pre','CR_post']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b7a0ac8-58ad-410b-a1de-82f8bc6b86db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop the na's\n",
    "trees_dat = trees_dat.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f37bc967-5fb6-4bfc-bc7c-0f0859bc9305",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36509"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees_dat.shape[0]\n",
    "# this gives us the number of observations left after dropping the incomplete ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf806bf",
   "metadata": {},
   "source": [
    "## Step 3: Data Preprocessing\n",
    "1. We recode categorical predictors to zero-based integer form because most machine learning models, including logistic regression, cannot work directly with categorical data represented as strings or labels. Instead, models require numerical input. Let's do that here. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0d879c7-50f9-4332-a40e-8b4f671290a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 36509 entries, 500 to 169336\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   yr1status      36509 non-null  int64  \n",
      " 1   YrFireName     36509 non-null  object \n",
      " 2   Times_burned   36509 non-null  int64  \n",
      " 3   Species        36509 non-null  object \n",
      " 4   Genus_species  36509 non-null  object \n",
      " 5   DBH_cm         36509 non-null  float64\n",
      " 6   HT_m           36509 non-null  float64\n",
      " 7   CR_pre         36509 non-null  float64\n",
      " 8   CR_post        36509 non-null  float64\n",
      "dtypes: float64(4), int64(2), object(3)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "trees_dat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e41fb79-ad31-4162-ac76-887461bb4160",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yr1status</th>\n",
       "      <th>YrFireName</th>\n",
       "      <th>Times_burned</th>\n",
       "      <th>Species</th>\n",
       "      <th>Genus_species</th>\n",
       "      <th>DBH_cm</th>\n",
       "      <th>HT_m</th>\n",
       "      <th>CR_pre</th>\n",
       "      <th>CR_post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>71.374</td>\n",
       "      <td>41.76</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.622</td>\n",
       "      <td>12.80</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46.228</td>\n",
       "      <td>34.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.082</td>\n",
       "      <td>23.16</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.384</td>\n",
       "      <td>26.21</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     yr1status  YrFireName  Times_burned  Species  Genus_species  DBH_cm  \\\n",
       "500          0          37             1        0              0  71.374   \n",
       "501          0          37             1        0              0  23.622   \n",
       "502          0          37             1        0              0  46.228   \n",
       "503          0          37             1        0              0  21.082   \n",
       "504          0          37             1        0              0  24.384   \n",
       "\n",
       "      HT_m  CR_pre  CR_post  \n",
       "500  41.76    0.84     0.74  \n",
       "501  12.80    0.60     0.57  \n",
       "502  34.75    0.75     0.59  \n",
       "503  23.16    0.38     0.38  \n",
       "504  26.21    0.42     0.42  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recode categorical predictors to zero-based integer form\n",
    "for col in ['Genus_species', 'YrFireName', 'Species']:\n",
    "    trees_dat[col],_ = pd.factorize(trees_dat[col], sort=True)\n",
    "    \n",
    "# Check\n",
    "trees_dat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcc4673-26dc-4c09-8c9a-0f2f97abe16f",
   "metadata": {},
   "source": [
    "2. Then we'll split into training and test data and scale for coefficient interpretability.  Recall that we use the training features to calculate our scaling parameters (mean and standard deviation) and apply the scaling to those training features (`scaler.fit_transform`) and then apply the scaling to the features in the test data as well (`scaler.transform`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b2f9d2-f414-4bf2-b0a3-51d55f3d997a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3055eca1-9c22-4266-95a0-710b43be5a8e",
   "metadata": {},
   "source": [
    "3. How many training/test observations do we have? Print your answer in the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb4803d-8680-4ede-b790-3579f4a485e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "# Verify the training and testing set size\n",
    "print(\"Training set observations:\", )\n",
    "print(\"Testing set observations:\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca8857c",
   "metadata": {},
   "source": [
    "## Step 4: Train a Logistical Model\n",
    "Create a classifier using `LogisticRegression()` and fit it on the training data.  Then assess the model's accuracy on the training set by making predictions on the training data.  Calculate and **print** the accuracy of your model on the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578b2ca5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "print(f\"Training Accuracy: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d86616",
   "metadata": {},
   "source": [
    "## Step 5: Test Set Predictions and Model Evaluation\n",
    "Now let's take our trained logistic classifier and make predictions on the test set. Calculate the accuracy and confusion matrix. Then use `sns.heatmap` for improved confusion matrix visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4e4d6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Accuracy: \")\n",
    "\n",
    "\n",
    "#Plot confusion matrix\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5cdbbb",
   "metadata": {},
   "source": [
    "## Step 6: Logistic Classifier Evaluation\n",
    "How did your model perform on the unseen data? \n",
    "Does your model perform differently on observations of trees that survived vs trees that died?\n",
    "Is there a class imbalance in this data set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c651ef7",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60c7e36",
   "metadata": {},
   "source": [
    "## Step 7: What about a Dummy?\n",
    "What do you think would happen if we built a model that always predicts the majority class (dead trees)? How would its accuracy compare to your logistic regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66ba576",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6854360d",
   "metadata": {},
   "source": [
    "Let's go ahead and do it: use `DummyClassifier()` with the appropriate value for the 'strategy' parameter to train a majority classifier.  Then calculate this model's accuracy on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5b4015",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "# Print accuracy and confusion matrix results\n",
    "print(f\"Dummy Accuracy: \")\n",
    "print(\"\\nDummy Confusion Matrix:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3445d23",
   "metadata": {},
   "source": [
    "# Step 8: ROCs and AUCs\n",
    "Our two models have similar accuracy, but is that all there is to this story?  Let's dig a little deeper on the comparison of our logistic and dummy classifiers by examining the associated receiver-operator characteristic (ROC) curves. Calculate the area under the curve (AUC) for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef8515b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Logistic classifier AUC\n",
    "...\n",
    "print(f\"Logistic AUC: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5180e8b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dummy classifier AUC\n",
    "...\n",
    "print(f\"Dummy AUC: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acd252f",
   "metadata": {},
   "source": [
    "# Step 9: Plot dummy and logistic model ROC curves\n",
    "Now using the outputs from `roc_curve()`, plot the ROC curves for both models on the same plot.  Make sure to use appropriate labels in the legend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a7fe29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec104e80",
   "metadata": {},
   "source": [
    "How do the two models compare on AUC?  What are the implications for evaluating classifiers based on accuracy of their predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ab1a30",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1767d77",
   "metadata": {},
   "source": [
    "# Step 10: Final interpretation\n",
    "\n",
    "Identifying the most important features in a model can guide decision-making. For instance, in our dataset, highly important features might indicate key factors affecting tree survival after a fire. We will calculate the feature importance by examining the coefficients of our logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a97e03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "# Print the sorted feature importance\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d9db5d",
   "metadata": {},
   "source": [
    "Which are the most important features in our model (reference the metadata to help answer this)? Can you think of any implications for forest management or conservation strategy?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd42e56c",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda 3 (EDS232)",
   "language": "python",
   "name": "ml-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
